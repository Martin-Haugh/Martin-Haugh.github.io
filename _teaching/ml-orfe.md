---
layout: archive
title: "IEOR E4525: Machine Learning for OR & FE (Columbia University)"
permalink:  /teaching/ml-orfe/
author_profile: true
---
### IEOR E4525: Machine Learning for OR & FE (Columbia University)

I last taught this advanced-level MS course in spring 2017 in the IE&OR Department at Columbia University. 
It's an elective course for the MS in Financial Engineering and MS in Operations Research programs at Columbia. 
Because the selection of topics varied over the years there is considerably more material here than could be 
covered in a single course. Rather than identifying what topics (or subsets of topics) were covered each year, 
I have simply provided a list of topics that were covered in some version of the course. 
<!---
I have also provided 
some additional slides / topics that never made it into the course but that I nonetheless used / developed at 
some point for other purposes. If a link isn’t provided then that simply means I do not wish to post the slides 
(probably because I am in the ``process'' of editing them – a process that could take a very long time indeed). 
I will not be posting solutions to the assignments or code / software so please don’t send me an email asking 
me to do so!  Finally, please note that I do not have time to answer emails asking me to clarify or explain 
issues arising in these notes and assignments. 
--->
A syllabus and description of the course logistics from spring 2017 (when I co-taught the course with Garud 
Iyengar) can be found here.  I'm also grateful to the excellent textbooks of (1) [James, Witten, Hastie & 
Tibshirani](http://www.statlearning.com/) (2) [David Barber](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage) and (3) [Christopher Bishop](https://www.microsoft.com/en-us/research/people/cmbishop/). Many of the figures in the slides below were taken from these sources. 

### Lecture Slides (and Occasional Notes)

0. Very Brief Introduction to Machine Learning
1. Regression I (Linear regression, bias-variance decomposition)
2. Classification I (k-NN, Naïve Bayes, LDA & QDA, logistic regression, optimal Bayes classifier, reduced-rank LDA)
3. Resampling Methods (Bootstrap; cross-validation)
4. Regression II (Subset selection, ridge regression, Lasso etc.)
5. Classification II (Classification & Regression Trees, Bagging, Random Forests & Boosting)
6. Clustering
7. An Introduction to Causality
8. Support Vector Machines
9. Kernels & the Kernel Trick (including reproducing kernel Hilbert spaces (RKHS))
10. The EM Algorithm (Notes and slides)
11. Dimension Reduction Methods (PCA, kernel PCA, recommender systems and matrix factorization, PageRank)
12. Hidden Markov Models (HMMs)
13. Bayesian Models and MCMC (Notes and slides from my Monte-Carlo Simulation course)
14. Introduction to Graphical Models (Directed acyclic graphs (DAGs) and Markov random fields)
15. Variational Inference (KL divergence, variational Bayes, expectation propagation)
